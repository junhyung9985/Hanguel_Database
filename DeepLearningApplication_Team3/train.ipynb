{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "from PIL import Image\n",
    "import csv\n",
    "from os import walk\n",
    "from os.path import isfile, join\n",
    "from os import listdir\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "\n",
    "train_path = \"../Hanguel_Database/Image_train\"\n",
    "test_path = \"../Hanguel_Database/Image_test\"\n",
    "#ts = \"/content/drive/My Drive/DeepLearning_group3/Hanguel_Database/Image_test\"\n",
    "\n",
    "def findFiles(path):\n",
    "    onlyfiles = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    return onlyfiles\n",
    "\n",
    "test_file = findFiles(test_path)\n",
    "train_file = findFiles(train_path)\n",
    "\n",
    "\n",
    "test_dir = \"../Hanguel_Database/test\"\n",
    "train_dir = \"../Hanguel_Database/train\"\n",
    "\n",
    "label = open('labels.csv', 'r', encoding='utf-8')\n",
    "rdr = csv.reader(label)\n",
    "for line in rdr:\n",
    "    line = line[0]\n",
    "    save_ts = test_dir+\"/\"+line\n",
    "    save_tr = train_dir+\"/\"+line\n",
    "    if (os.path.exists(save_ts)==False): os.makedirs(os.path.join(save_ts))\n",
    "    if (os.path.exists(save_tr)==False): os.makedirs(os.path.join(save_tr))\n",
    "\n",
    "for f in train_file:\n",
    "    fi = f.split('_')\n",
    "    class_name = fi[0]\n",
    "    num = (fi[1].split('.'))[0]\n",
    "    ls = list(csv.reader(open(join(train_path, f), newline=''), delimiter=','))\n",
    "    lst = []\n",
    "    for tmp in ls:\n",
    "        temp = [a for a in tmp if a!='']\n",
    "        lst.append(temp)\n",
    "    print(lst)\n",
    "    matrix = np.array(lst).astype(\"uint8\")\n",
    "    imgObj = Image.fromarray(matrix)\n",
    "    resized_imgObj = imgObj.resize((28, 28))\n",
    "    resized_imgObj.save(\"../Hanguel_Database/train/{}/{}.jpg\".format(class_name,num))\n",
    "'''\n",
    "# Training_set을 ImageLoader와 호환할 수 있게 해주는 코드\n",
    "'''\n",
    "\n",
    "train_path = \"../Hanguel_Database/Image_train\"\n",
    "test_path = \"../Hanguel_Database/Image_test\"\n",
    "#ts = \"/content/drive/My Drive/DeepLearning_group3/Hanguel_Database/Image_test\"\n",
    "\n",
    "def findFiles(path):\n",
    "    onlyfiles = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    return onlyfiles\n",
    "\n",
    "test_file = findFiles(test_path)\n",
    "train_file = findFiles(train_path)\n",
    "\n",
    "test_dir = \"../Hanguel_Database/test\"\n",
    "train_dir = \"../Hanguel_Database/train\"\n",
    "\n",
    "label = open('labels.csv', 'r', encoding='utf-8')\n",
    "rdr = csv.reader(label)\n",
    "for line in rdr:\n",
    "    line = line[0]\n",
    "    save_ts = test_dir+\"/\"+line\n",
    "    save_tr = train_dir+\"/\"+line\n",
    "    if (os.path.exists(save_ts)==False): os.makedirs(os.path.join(save_ts))\n",
    "    if (os.path.exists(save_tr)==False): os.makedirs(os.path.join(save_tr))\n",
    "\n",
    "for f in test_file:\n",
    "    fi = f.split('_')\n",
    "    class_name = fi[0]\n",
    "    num = (fi[1].split('.'))[0]\n",
    "    ls = list(csv.reader(open(join(test_path, f), newline=''), delimiter=','))\n",
    "    lst = []\n",
    "    for tmp in ls:\n",
    "        temp = [a for a in tmp if a!='']\n",
    "        lst.append(temp)\n",
    "    print(lst)\n",
    "    matrix = np.array(lst).astype(\"uint8\")\n",
    "    imgObj = Image.fromarray(matrix)\n",
    "    resized_imgObj = imgObj.resize((28, 28))\n",
    "    resized_imgObj.save(\"../Hanguel_Database/test/{}/{}.jpg\".format(class_name,num))\n",
    "\n",
    "\n",
    "'''\n",
    "# Test_set을 ImageLoader와 호환할 수 있게 해주는 코드\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN(nn.Module):\n",
    "    def __init__(self, output_dim=10):\n",
    "        super(MyCNN,self).__init__()\n",
    "\n",
    "        self.output_dim=output_dim\n",
    "\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            nn.Conv2d(3,32,3,padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,32,3,padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2), # 32 x (14x14)\n",
    "            \n",
    "            nn.Conv2d(32,16,3,padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16,16,3,padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2) # 16 x (7x7)\n",
    "        )\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(16*7*7,100),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100,output_dim)\n",
    "        )       \n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.cnn_layers(x)\n",
    "        out = out.view(out.shape[0],-1)\n",
    "        out = self.fc_layer(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "learning_rate = 0.001\n",
    "output_dim=2350\n",
    "\n",
    "model = MyCNN(output_dim=output_dim).cuda()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "param_list = list(model.children())\n",
    "print(param_list)\n",
    "\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(28,28),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.3, 0.3, 0.3])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(28,28),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.3, 0.3, 0.3])\n",
    "    ]),\n",
    "}\n",
    "test_transform = data_transforms['test']\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "test_batch_size = 10\n",
    "data_dir = '/home/junhyung9985/Hanguel_Database/'\n",
    "train_dir = 'train'\n",
    "test_dir = 'test'\n",
    "\n",
    "train_set = datasets.ImageFolder(data_dir+train_dir, data_transforms['train'])\n",
    "test_set = datasets.ImageFolder(test_dir, test_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
    "                                              shuffle=True, num_workers=4)          \n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=test_batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "train_size = len(train_set)\n",
    "test_size = len(test_set)\n",
    "\n",
    "class_names = train_set.classes\n",
    "\n",
    "print(class_names) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result_dir = '/home/junhyung9985/Hanguel_Database/result'\n",
    "num_epoch = 20\n",
    "\n",
    "if not os.path.exists(result_dir):\n",
    "    os.mkdir(result_dir)    \n",
    "    \n",
    "for i in range(num_epoch):\n",
    "    model.train()\n",
    "    for j, [image,label] in enumerate(train_loader):\n",
    "        x = image.cuda()\n",
    "        y_= label.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = loss_func(output,y_)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if j % 30 == 0:\n",
    "            print(i,j, loss.data.cpu())\n",
    "\n",
    "print('training is done by max_epochs', num_epoch)\n",
    "torch.save(model, result_dir + '/epoch_{}_lr_{}.model'.format(num_epoch, learning_rate))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
